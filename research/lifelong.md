---
layout: page
title: Lifelong Person Re-Identification
permalink: research/lifelong
---

Person re-identification (ReID) methods always learn through a stationary domain that is fixed by the choice of a given dataset. In many contexts (e.g., lifelong learning), those methods are ineffective because the domain is continually changing in which case incremental learning over multiple domains is required potentially. In this work we explore a new and challenging ReID task, namely lifelong person re-identification (LReID), which enables to learn continuously across multiple domains and even generalise on new and unseen domains. Following the cognitive processes in the human brain, we design an Adaptive Knowledge Accumulation (AKA) framework that is endowed with two crucial abilities: knowledge representation and knowledge operation. Our method alleviates catastrophic forgetting on seen domains and demonstrates the ability to generalize to unseen domains. Correspondingly, we also provide a new and large-scale benchmark for LReID. Extensive experiments demonstrate our method outperforms other competitors by a margin of 5.8% mAP in generalising evaluation.

Person re-identification (ReID) seeks to linking the same pedestrian across disjoint camera views. While advanced
deep learning methods have shown powerful abilities for ReID, their training process is limited heavily by a fixed and stationary dataset. However, this limitation violates many practical scenarios where the data is continuously increasing from different domains. For instance, smart surveillance systems over multiple crossroads capture millions of new images every day, and they are required to have the ability of incremental or lifelong learning.

To overcome the above limitation, we propose a new yet practical ReID task, namely lifelong person reidentification (LReID), which requires the model to accumulate informative knowledge incrementally from several
seen domains and then adapt the knowledge to the test sets of both seen and unseen domains (Fig. 1). Our LReID
task has two challenging problems, compared to previous tasks. First, unlike conventional lifelong learning, LReID further considers improving the generalization ability on unseen classes that never appear in the lifelong training stage. Second, LReID is a fine-grained lifelong learning task, in which inter-class appearance variations are significantly subtler than standard lifelong learning benchmarks like CIFAR-100 and ImageNet.

To tackle the challenges in LReLD, we propose a new adaptive knowledge accumulation (AKA) framework which can continually accumulate knowledge information from old domains, so as to have a better generalization quality on any new domain. This idea is inspired by a new perspective of human cognitive processes. Recent discoveries in cognitive science indicate that a cognitive process could be broadly decomposed into “representations” and “operations”. The structure of the knowledge representations (KRs) plays a key role for stabilizing memory, which shows our brain has potential relations with graph structure. Adaptive update and retrieval contained in the knowledge operations (KOs) promotes the efficient use of knowledge. Such complex yet elaborate KRs and KOs enable our brain to perform life-long learning well. Motivated by this, we endow AKA with two abilities to separately accomplish knowledge representation and knowledge operation. Specifically, we first represent transferable knowledge as a knowledge graph (KG), where each vertex represents one type of knowledge (e.g., the similar appearance between two persons). For image samples in one mini-batch, we temporally construct a similarity graph based on their relationships. Then, AKA establishes cross-graph links and executes a graph convolution. Such operation enables KG to transfer previous knowledge to each current sample. Meanwhile, KG is updated by summarizing the information underlying the relationships among current instances. Furthermore, for encouraging KG to improve learned representation while considering the forgetting problem, plasticity loss and stability loss are integrated to achieve an optimal balance for generalization on unseen domain. Our contributions are three-fold: Task contribution. We exploit a new yet practical person ReID task, namely LReID, which considers person reidentification problem under a lifelong learning scenario. Technical contribution. We propose a new AKA framework for LReID. AKA maintains a learnable knowledge graph to adaptively update previous knowledge, while transferring the knowledge to improve generalization on any unseen domains, with the plasticity-stability loss. Empirical contribution. We provide a new benchmark and evaluation protocols for LReID. AKA shows promising improvements over other state-of-the-art methods.
